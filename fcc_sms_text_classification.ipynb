{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RZOuS9LWQvv"
      },
      "outputs": [],
      "source": [
        "#importing some libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMHwYXHXCar3"
      },
      "outputs": [],
      "source": [
        "#downloading the data files\n",
        "\n",
        "TRAIN_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/train-data.tsv\"\n",
        "TEST_DATA_URL = \"https://raw.githubusercontent.com/beaucarnes/fcc_python_curriculum/master/sms/valid-data.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_h508FEClxO"
      },
      "outputs": [],
      "source": [
        "#testing and training\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train-data.tsv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"valid-data.tsv\", TEST_DATA_URL)\n",
        "\n",
        "df_train = pd.read_csv(train_file_path, sep=\"\\t\", header=None, names=['y', 'x'])\n",
        "df_test = pd.read_csv(test_file_path, sep=\"\\t\", header=None, names=['y', 'x'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMKywn4zReN"
      },
      "outputs": [],
      "source": [
        "#cleaning thd data_set\n",
        "\n",
        "def clean_txt(txt):\n",
        "    txt = re.sub(r'([^\\s\\w])+', ' ', txt)\n",
        "    txt = \" \".join([lemmatizer.lemmatize(word) for word in txt.split() if not word in stopwords_eng])\n",
        "    txt = txt.lower()\n",
        "    return txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9tD9yACG6M9"
      },
      "outputs": [],
      "source": [
        "#preprocessing the text messages\n",
        "\n",
        "stopwords_eng = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "X_train = df_train['x'].apply(lambda x: clean_txt(x))\n",
        "\n",
        "max_words = 1000\n",
        "max_len = 500\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Tokenizer\n",
        "\n",
        "t = Tokenizer(num_words=max_words)\n",
        "t.fit_on_texts(X_train)\n",
        "\n",
        "sequences = t.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Define the model\n",
        "i = tf.keras.layers.Input(shape=[max_len])\n",
        "x = tf.keras.layers.Embedding(max_words, 50, input_length=max_len)(i)\n",
        "x = tf.keras.layers.LSTM(64)(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=i, outputs=x)\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='RMSprop',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "HigXQZTO_C4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "\n",
        "r = model.fit(sequences_matrix, df_train['y'].map({'ham': 0, 'spam': 1}),\n",
        "              batch_size=256, epochs=10, validation_split=0.02,\n",
        "              callbacks=[tf.keras.callbacks.EarlyStopping(\n",
        "                  monitor='val_loss', min_delta=0.0001)])\n"
      ],
      "metadata": {
        "id": "exNkiuv5_U0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_messages(messages):\n",
        "    cleaned_messages = messages.apply(lambda x: clean_txt(x))\n",
        "    sequences = t.texts_to_sequences(cleaned_messages)\n",
        "    sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len)\n",
        "    return sequences_matrix\n",
        "\n",
        "def predict_message(pred_text):\n",
        "    preprocessed_text = preprocess_messages(pd.Series([pred_text]))\n",
        "    prediction = model.predict(preprocessed_text)[0][0]\n",
        "    label = \"ham\" if prediction < 0.01 else \"spam\"\n",
        "    return [prediction, label]\n"
      ],
      "metadata": {
        "id": "hVO5w1Yd_arc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the predictions\n",
        "def test_predictions():\n",
        "    test_messages = [\"how are you doing today\",\n",
        "                     \"sale today! to stop texts call 98912460324\",\n",
        "                     \"i dont want to go. can we try it a different day? available sat\",\n",
        "                     \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                     \"you have won Â£1000 cash! call to claim your prize.\",\n",
        "                     \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                     \"wow, is your arm alright. that happened to me one time too\"\n",
        "                    ]\n",
        "\n",
        "    test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "    passed = True\n",
        "\n",
        "    for msg, ans in zip(test_messages, test_answers):\n",
        "        prediction = predict_message(msg)\n",
        "        if prediction[1] != ans:\n",
        "            passed = False\n",
        "\n",
        "    if passed:\n",
        "        print(\"You passed the challenge. Great job!\")\n",
        "    else:\n",
        "        print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ],
      "metadata": {
        "id": "crG7RZbQ_dcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing some more messages\n",
        "\n",
        "def test_predictions():\n",
        "    test_messages_list = [\"Hello, how are you?\",\n",
        "                          \"Congratulations! You won a prize!\",\n",
        "                          \"Lahore da pawa Akthar Lava\",\n",
        "                          \"Can you pick me up from the station?\",\n",
        "                          \"Sure I will pick them up for you.\"\n",
        "                          \"I'll see you tomorrow.\",\n",
        "                          \"URGENT: Your account has been compromised.\",\n",
        "                          \"Have a great day!\",\n",
        "                          \"You Just Won 100$\",\n",
        "                          \"Verify your bank account\"]\n",
        "\n",
        "    for msg in test_messages_list:\n",
        "        prediction = predict_message(msg)\n",
        "        print(f\"Message: '{msg}' --> Prediction: {prediction[1]} (Likelihood: {prediction[0]:.5f})\")\n",
        "\n",
        "test_predictions()\n"
      ],
      "metadata": {
        "id": "Mk-UDjihAMVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fpaf8SIrA3_w"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "fcc_sms_text_classification.ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {}
  },
  "nbformat": 4,
  "nbformat_minor": 0
}